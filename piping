#save
1. open stream
2. pipe into filters *
    - filters might be [
        addUncommittedEvents filter
    ]
3. pipe into commit stream

#get
1. open stream
2. pipe stream into aggregate creation 
3. //do work

repo.get entityFn, '123', (err, agg) ->
    //do stuff wtih agg
    repo.save agg





aggregate:revision HASH
    '123': 4

commit2score => LIST
    {'123':'1'} => commit#1
    {'123':'4'} => commit#2
    
commits:123 SORTED SET
    ---score 1
    {
        commitSequence: 3 => needed?
        payload: [...]
        headers: [...]
        timestamp: {...}
    }
    ---score 4
    {
        commitSequence: 4 => needed?
        payload: [3events]
        headers: []
        timestamp: {}
    }



reading all events
1. needs to support time bound streaming
--- perhaps 'score' for a sorted set could be the Date().getTime()?
reader.

